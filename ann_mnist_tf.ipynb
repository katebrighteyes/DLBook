{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "vjupyter",
      "language": "python",
      "name": "vjupyter"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "ann_mnist_tf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WQr-C1pGzjq"
      },
      "source": [
        "# 심층 신경망 Tensorflow 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmSHFPB1G4vJ"
      },
      "source": [
        "* Tensorflow 환경 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "R8AKGYlOExBj",
        "outputId": "452df46d-5e62-4c05-ad10-d2aa4addb060"
      },
      "source": [
        "pip install setuptools==44.0.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting setuptools==44.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/d3/955738b20d3832dfa3cd3d9b07e29a8162edb480bf988332f5e6e48ca444/setuptools-44.0.0-py2.py3-none-any.whl (583kB)\n",
            "\r\u001b[K     |▋                               | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 16.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 10.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 5.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 102kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 112kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 122kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 133kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 143kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 153kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 174kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 194kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 204kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 215kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 225kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 245kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 256kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 266kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 276kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 286kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 296kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 307kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 317kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 327kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 337kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 348kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 358kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 368kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 378kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 389kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 399kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 409kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 419kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 430kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 440kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 450kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 460kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 471kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 481kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 491kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 501kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 512kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 522kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 532kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 542kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 552kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 563kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 573kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 583kB 6.1MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 51.1.1\n",
            "    Uninstalling setuptools-51.1.1:\n",
            "      Successfully uninstalled setuptools-51.1.1\n",
            "Successfully installed setuptools-44.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7zowpunFNQk",
        "outputId": "f950e5a7-3dec-42cf-b1fa-a79a63be8e46"
      },
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.19.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (44.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru0M0oTEFfe7",
        "outputId": "d4b3e721-de66-4a44-dc76-af0219ff20d4"
      },
      "source": [
        "pip install Cython contextlib2 matplotlib pillow lxml gast==0.2.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=d24177a90588809e01657d0d9a8aab1ecdf8cf528c4fab37501987b4b54b85d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfOrMTaXHE6R"
      },
      "source": [
        "# 코드 시작"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bThiqRyTGjUD"
      },
      "source": [
        "1. 패키지 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pff8WAboEmQq",
        "outputId": "8b0badc4-2d52-465d-e34c-b969da4c5526"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd3_kp73EmQr"
      },
      "source": [
        "2. mnist 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhHBWHiXEmQs",
        "outputId": "7baf8e09-a014-4764-ce0a-62381ec788ec"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"./temp/MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-528e6251c846>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./temp/MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./temp/MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./temp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./temp/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHRAg57pEmQs"
      },
      "source": [
        "3. 하이퍼파라미터 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUTd11b3EmQt"
      },
      "source": [
        "learning_rate = 0.01\n",
        "epochs = 40    \n",
        "minibatch = 128   \n",
        "display_step = 1   \n",
        "input_size = 784   \n",
        "h1_size = 256\n",
        "h2_size = 256\n",
        "output_size = 10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8FAM_-nEmQt"
      },
      "source": [
        "4. 플레이스홀더 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ugWCgYiEmQu"
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, input_size])\n",
        "y = tf.placeholder(tf.float32, shape=[None, output_size])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjwoRtpyEmQu"
      },
      "source": [
        "5. 3 레이어 신경망 모델 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg45jUedEmQu"
      },
      "source": [
        "def ANN_fuction(x):\n",
        "    W1 = tf.Variable(tf.random_normal(shape=[input_size, h1_size]))\n",
        "    b1 = tf.Variable(tf.random_normal(shape=[h1_size]))\n",
        "    H1_output = tf.nn.relu(tf.matmul(x,W1) + b1)\n",
        "    W2 = tf.Variable(tf.random_normal(shape=[h1_size, h2_size]))\n",
        "    b2 = tf.Variable(tf.random_normal(shape=[h2_size]))\n",
        "    H2_output = tf.nn.relu(tf.matmul(H1_output,W2) + b2)\n",
        "    W_output = tf.Variable(tf.random_normal(shape=[h2_size, output_size]))\n",
        "    b_output = tf.Variable(tf.random_normal(shape=[output_size]))\n",
        "    logits = tf.matmul(H2_output,W_output) + b_output\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpxAqN5QEmQv"
      },
      "source": [
        "6. 신경망 모델 함수 호출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7OCbliYEmQv"
      },
      "source": [
        "logits = ANN_fuction(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koPSZK_nEmQv"
      },
      "source": [
        "7. 손실함수와 최적화 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzVpAbZGEmQw"
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2( logits=logits, labels=y))\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwNud78WEmQw"
      },
      "source": [
        "8. 세션 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37x_n5sKEmQw",
        "outputId": "b6d0492e-82ea-4a8a-9d2a-ef3161321431"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    # 훈련 시작\n",
        "    for epoch in range(epochs):\n",
        "        average_loss = 0.\n",
        "        total_batch = int(mnist.train.num_examples/minibatch)\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = mnist.train.next_batch(minibatch)\n",
        "            _, current_loss = sess.run([train_step, loss], feed_dict={x: batch_x, y: batch_y})\n",
        "        average_loss += current_loss / total_batch\n",
        "        \n",
        "        # 훈련 상태(현재 에포크의 손실 값) 출력\n",
        "        if epoch % display_step == 0:\n",
        "            print(\"[Epoch] %d, [Loss] %f\" % ((epoch+1), average_loss))\n",
        "\n",
        "    # 모델 정확도 계산\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    print(\"[Accuracy] %f\" % (accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels})))\n",
        "    \n",
        "    # 랜덤 데이터 예측 테스트\n",
        "    r = random.randint(0, mnist.test.num_examples - 1)\n",
        "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
        "    print(\"Prediction: \", sess.run(tf.argmax(logits, 1), feed_dict={x: mnist.test.images[r:r + 1]}))    \n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch] 1, [Loss] 0.043127\n",
            "[Epoch] 2, [Loss] 0.053478\n",
            "[Epoch] 3, [Loss] 0.012030\n",
            "[Epoch] 4, [Loss] 0.007164\n",
            "[Epoch] 5, [Loss] 0.010753\n",
            "[Epoch] 6, [Loss] 0.021092\n",
            "[Epoch] 7, [Loss] 0.008804\n",
            "[Epoch] 8, [Loss] 0.010269\n",
            "[Epoch] 9, [Loss] 0.006394\n",
            "[Epoch] 10, [Loss] 0.008360\n",
            "[Epoch] 11, [Loss] 0.004178\n",
            "[Epoch] 12, [Loss] 0.000000\n",
            "[Epoch] 13, [Loss] 0.003857\n",
            "[Epoch] 14, [Loss] 0.002032\n",
            "[Epoch] 15, [Loss] 0.003479\n",
            "[Epoch] 16, [Loss] 0.001902\n",
            "[Epoch] 17, [Loss] 0.000123\n",
            "[Epoch] 18, [Loss] 0.002330\n",
            "[Epoch] 19, [Loss] 0.001159\n",
            "[Epoch] 20, [Loss] 0.004583\n",
            "[Epoch] 21, [Loss] 0.001434\n",
            "[Epoch] 22, [Loss] 0.000078\n",
            "[Epoch] 23, [Loss] 0.001458\n",
            "[Epoch] 24, [Loss] 0.000415\n",
            "[Epoch] 25, [Loss] 0.001377\n",
            "[Epoch] 26, [Loss] 0.001116\n",
            "[Epoch] 27, [Loss] 0.000000\n",
            "[Epoch] 28, [Loss] 0.000043\n",
            "[Epoch] 29, [Loss] 0.000214\n",
            "[Epoch] 30, [Loss] 0.000935\n",
            "[Epoch] 31, [Loss] 0.000052\n",
            "[Epoch] 32, [Loss] 0.000000\n",
            "[Epoch] 33, [Loss] 0.000002\n",
            "[Epoch] 34, [Loss] 0.000001\n",
            "[Epoch] 35, [Loss] 0.000288\n",
            "[Epoch] 36, [Loss] 0.000000\n",
            "[Epoch] 37, [Loss] 0.000286\n",
            "[Epoch] 38, [Loss] 0.000750\n",
            "[Epoch] 39, [Loss] 0.000000\n",
            "[Epoch] 40, [Loss] 0.000224\n",
            "[Accuracy] 0.935200\n",
            "Label:  [8]\n",
            "Prediction:  [8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIE8YThWEmQx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}